{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# 1. Import libraries\n",
    "# Core libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Machine learning - Scikit-learn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestRegressor,\n",
    "    BaggingRegressor,\n",
    "    GradientBoostingRegressor,\n",
    "    ExtraTreesRegressor\n",
    ")\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "# Other ML libraries\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostRegressor\n",
    "# Deep learning - TensorFlow/Keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Load dataset\n",
    "#df = pd.read_csv(\"pure state for 5.csv\") \n",
    "J1=0.5\n",
    "df = pd.read_csv(\"Pure states training for \"+str(J1)+\".csv\") \n",
    "df=df.dropna()\n",
    "X = df.drop(columns=[\"N\"])\n",
    "y = df[\"N\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (9999, 6)\n",
      "X shape: (9999, 5)\n",
      "y shape: (9999,)\n"
     ]
    }
   ],
   "source": [
    "# Explor The Data\n",
    "print(\"Data shape:\",df.shape)\n",
    "print(\"X shape:\",X.shape)\n",
    "print(\"y shape:\",y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Scale features (for NN)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_scaled = scaler.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ahmed167010\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# 5. Build and train Neural Network\n",
    "nn_model = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "nn_model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "nn_history = nn_model.fit(\n",
    "    X_train_scaled, y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=100,\n",
    "    batch_size=128,\n",
    "    callbacks=[early_stop],\n",
    "    verbose=0\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training and validation loss from the history\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(nn_history.history['loss'], label='Training Loss')\n",
    "plt.plot(nn_history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Neural Network - Epochs vs Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss (MSE)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Train XGBoost model\n",
    "xgb_model = xgb.XGBRegressor(\n",
    "    objective='reg:squarederror',\n",
    "    n_estimators=200,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=5,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "xgb_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Train ُExtra Trees model\n",
    "et_model = ExtraTreesRegressor(\n",
    "    n_estimators=200,\n",
    "    max_depth=10,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "et_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Predict with both models\n",
    "nn_pred = nn_model.predict(X_test_scaled).flatten()\n",
    "xgb_pred = xgb_model.predict(X_test)\n",
    "et_pred = et_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. Evaluate models\n",
    "def evaluate_model(y_true, y_pred, name=\"Model\"):\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    print(f\"{name} Performance:\")\n",
    "    print(f\"  MSE: {mse:.6f}\")\n",
    "    print(f\"  MAE: {mae:.6f}\")\n",
    "    print(f\"  R²: {r2:.6f}\\n\")\n",
    "\n",
    "evaluate_model(y_test, nn_pred, \"Neural Network\")\n",
    "evaluate_model(y_test, xgb_pred, \"XGBoost\")\n",
    "evaluate_model(y_test, et_pred, \"Extra Trees\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Integrating predictions as inputs to the meta-learner\n",
    "meta_X = np.column_stack((nn_pred, xgb_pred, et_pred))\n",
    "meta_y = y_test\n",
    "# Tain the meta-learner (GradientBoostingRegressor)\n",
    "#model=MLPRegressor(activation='relu', hidden_layer_sizes=(100,100), max_iter=2000, random_state=42)\n",
    "#model=RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "model=CatBoostRegressor(\n",
    "    n_estimators=1000,\n",
    "    early_stopping_rounds=100,\n",
    "    random_state=42,\n",
    "    verbose=100\n",
    ")\n",
    "#model=GradientBoostingRegressor(n_estimators=100, random_state=42)\n",
    "#model=ExtraTreesRegressor(max_depth=20, max_features=1.0, min_samples_leaf=1, n_estimators=300, random_state=42)\n",
    "#model=LinearRegression()\n",
    "meta_learner =model \n",
    "meta_learner.fit(meta_X, meta_y)\n",
    "\n",
    "# Predict the final results\n",
    "final_preds = meta_learner.predict(meta_X)\n",
    "\n",
    "# Calculate the metrics (R^2, MSE, MAE)\n",
    "r2 = r2_score(meta_y, final_preds)\n",
    "mse = mean_squared_error(meta_y, final_preds)\n",
    "mae = mean_absolute_error(meta_y, final_preds)\n",
    "\n",
    "# Print metrics results\n",
    "print(f\"R^2 Score of Stacking Model: {r2}\")\n",
    "print(f\"MSE of Stacking Model: {mse}\")\n",
    "print(f\"MAE of Stacking Model: {mae}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.scatter(y_test, final_preds, alpha=0.3, color='red',s=5)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'b-', lw=1.5,label=r\"$\\bar{\\mathcal{N}}$\"+r\"$=\\mathcal{N}$\")\n",
    "x1=y_test.min(); x2=y_test.max(); y1=final_preds.min(); y2=final_preds.max();\n",
    "m=round((y2-y1)/(x2-x1),3); c=round(y1-m*x1,3);\n",
    "plt.plot([y_test.min(), y_test.max()], [final_preds.min(), final_preds.max()], 'k--', lw=1.5,\\\n",
    "         label=r\"$\\bar{\\mathcal{N}}= $\"+str(m)+ r\"$ \\mathcal{N} $\"+str(c))\n",
    "plt.xlabel(r\"$\\mathcal{N}$\",fontsize=20)\n",
    "plt.ylabel(r\"$\\bar{\\mathcal{N}}$\",fontsize=20)\n",
    "plt.title(r\"(b)\",fontsize=20)\n",
    "plt.legend(fontsize=18)\n",
    "plt.grid(True)\n",
    "plt.axis(\"equal\")\n",
    "plt.xticks(fontsize=20)\n",
    "plt.yticks(fontsize=20)\n",
    "plt.ylim(0,1)\n",
    "plt.tight_layout()\n",
    "#plt.savefig(\"pure_state_one_meta.png\", dpi=800,bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################################################3\n",
    "##############################################################################################################\n",
    "##############################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 8. Predict with both models\n",
    "nn_p = nn_model.predict(X_scaled).flatten()\n",
    "xgb_p = xgb_model.predict(X)\n",
    "et_p = et_model.predict(X)\n",
    "# Integrating predictions as inputs to the meta-learner\n",
    "meta_X = np.column_stack((nn_p, xgb_p, et_p))\n",
    "meta_y = y\n",
    "\n",
    "# Tain the meta-learner (GradientBoostingRegressor)\n",
    "meta_learner = model\n",
    "\n",
    "meta_learner.fit(meta_X, meta_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The predicting for special class of states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tested_data=pd.read_csv(\"Pure states tested for \"+str(J1)+\".csv\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X=tested_data.drop('N',axis=1)\n",
    "y=tested_data['N']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_scaled = scaler.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Predict with both models\n",
    "nn_X = nn_model.predict(X_scaled).flatten()\n",
    "xgb_X = xgb_model.predict(X)\n",
    "et_X = et_model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Integrating predictions as inputs to the meta-learner\n",
    "meta_X_t = np.column_stack((nn_X, xgb_X, et_X))\n",
    "meta_learner.fit(meta_X_t,y)\n",
    "# Predict the final results\n",
    "y_pred = meta_learner.predict(meta_X_t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_iteration=len(y_pred)\n",
    "α=np.linspace(0,np.pi/2,number_iteration)\n",
    "plt.plot(α,tested_data['N'],color='blue',label=\"Exact for \"+r\"$J=0.5$\",linestyle='-')\n",
    "plt.plot(α,y_pred,color='red',label='Predicted for '+r\"$J=0.5$\",linestyle='--')\n",
    "# Set x-axis ticks at special points\n",
    "special_points = [0, np.pi/8, np.pi/4, 3*np.pi/8, np.pi/2]\n",
    "labels = [r\"$0$\", r\"$\\frac{\\pi}{8}$\", r\"$\\frac{\\pi}{4}$\", r\"$\\frac{3\\pi}{8}$\", r\"$\\frac{\\pi}{2}$\"]\n",
    "plt.title(r'(e)',fontsize=20)\n",
    "plt.xticks(special_points, labels)\n",
    "plt.xticks(fontsize=20)\n",
    "plt.yticks(fontsize=20)\n",
    "plt.ylim(0,1)\n",
    "plt.ylabel(r\"$\\mathcal{N}$\",fontsize=20)\n",
    "plt.legend(fontsize=18)\n",
    "plt.tight_layout()\n",
    "#plt.savefig(\"pure_state_one_tested.png\", dpi=800,bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 7443974,
     "sourceId": 11862445,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7757350,
     "sourceId": 12307144,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
